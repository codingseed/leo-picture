# 线程和进程的区别?

程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理 IO 的。

**当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。**

一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给CPU 执行

一个进程之内可以分为一到多个线程。

**二者对比**

- 进程是操作系统资源分配的基本单位
- 线程是CPU调度的基本单位，共享进程资源

进程是正在运行**程序的实例**，进程中包含了线程，每个线程执行不同的任务

不同的进程使用不同的内存空间，在**当前进程**下的所有**线程可以共享内存空间**

线程更轻量，线程上下文切换成本一般上要比进程上下文切换低(上下文切换指的是从一个线程切换到另一个线程)

# **并行和并发有什么区别?**

**单核CPU**

单核CPU下线程实际还是串行执行的

操作系统中有一个组件叫做任务调度器，将cpu的时间片(windows下时间片最小约为 15 毫秒)分给不同的程序使用，只是由于
cpu在线程间(**时间片**很短)的**切换非常快**，人类**感觉是同时运行**的。

总结为一句话就是:微观串行，宏观并行

一般会将这种**线程轮流使用CPU**的做法称为并发(concurrent)

**多核CPU**

每个核都可以调度运行线程，这时候线程可以是并行的，(core)

并发(concurrent)是同一时间应对(dealing with)多件事情的能力

并行(paralel)是同一时间动手做(doing)多件事情的能力



# 创建线程的方式有哪些?



共有四种方式可以创建线程，分别是

- 继承Thread类

- 实现runnable接口

- 实现Callable接口

- 线程池创建线程

  

## runnable 和 callable 有什么区别

- Runnable 接口run方法没有返回值
- Callable接口call方法有返回值，需要FutureTask获取结果
- Callable接口的cal()方法允许抛出异常;而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛

## 线程的 run()和 start()有什么区别?



**start()**:用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。start方法只能被调用一次。在方法调用时会进行状态校验，只有当前线程状态是new时才会成功执行。

**run()**:封装了要被线程执行的代码，可以被调用多次。多次调用 run ()，会在 “当前调用线程” 中**同步阻塞执行**（前一次 run () 执行完，才会执行下一次 run ()）



# 线程包括哪些状态，状态之间是如何变化的

新建(NEW)、可运行(RUNNABLE)、阻塞(BLOCKED)、等待(WAITING)、 时间等待(TIMED WALTING)、 终止(TERMINATED)

状态变化：

创建线程对象是**新建状态**

调用了start()方法转变为**可执行状态**

线程获取到了CPU的执行权，执行结束是**终止状态**

在可执行状态的过程中，如果没有获取CPU的执行权，可能会切换其他状态

- 如果没有获取锁(synchronized或lock)进入阻塞状态，获得锁再切换为可执行状态
- 如果线程调用了wait()方法进入等待状态，其他线程调用notify()唤醒后可切换为可执行状态
- 如果线程调用了sleep(50)方法，进入计时等待状态，到时间后可切换为可执行状态



# 新建 T1、T2、T3 三个线程，如何保证它们按顺序执行?

可以使用线程中的join方法解决
join()
等待线程运行结束

小例子:

其他线程中使用**t1.join()**

阻塞调用此方法的线程进入timed_waiting

直到线程t1执行完成后，此线程再继续执行

**notify()和 notifyAll()有什么区别?**

notifyAll:唤醒所有wait的线程
notify:只随机唤醒一个 wait 线程

# 在java中wait和sleep方法的不同?

**共同点**
wait()，wait(long)和 sleep(long)的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态。

**不同点**

**方法归属不同**

sleep(long)是 Thread 的静态方法
wait(long)都是 Obiect 的成员方法每个对象都有

**醒来时机不同**
执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来

wait(long)和 wait() 还可以被 notify 唤醒，wait() 如果不唤醒就一直等下去

它们都可以被打断唤醒

**锁特性不同(重点)**

wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制

wait 方法执行后会**释放对象锁**，允许其它线程获得该对象锁(我放弃cpu，但你们还可以用)

而 sleep 如果在 synchronized 代码块中执行，并**不会释放**对象锁(我放弃 cpu，你们也用不了)

# 如何停止一个正在运行的线程?

有三种方式可以停止线程：

1. 使用退**出标志**，使线程正常退出，也就是当run方法完成后线程终止，**仅能**在「线程运行中」判断标记状态来停止线程
2. 使用stop方法强行终止(不推荐，方法已作废)
3. **使用interrupt方法中断线程**：

- 打断阻塞的线程(sleep，wait，join)的线程，线程会抛出InterruptedException异常
- 打断正常的线程，可以根据打断状态来标记是否退出线程，不仅能在「线程运行中」生效，还能打断「线程阻塞状态」。



# synchronized关键字的底层原理

Synchronized【对象锁】采用互斥的方式让同一时刻至多只有一个线程能持有【对象锁】

## Monitor

![](D:\在图片\多线程\05.png)


它的底层由monitor实现的，monitor是jvm级别的对象(C++实现)，线程获得锁需要使用对象(锁)关联monitor

在monitor**内部有三个属性**，分别是owner、entrylist、waitset

其中owner关联的是获得锁的线程，并且只能关联一个线程;entrylist关联的是处于阻塞状态的线程;waitset关联的是处于Waiting状态的线程

## 锁升级过程

Java中的synchronized有偏向锁、轻量级锁、重量级锁三种形式，分别对应了锁只被**一个线程持有**、不同线程**交替持有锁**、多线程竞争锁三种情况。

![](D:\在图片\多线程\07.png)

**一旦锁发生了竞争，都会升级为重量级锁**

Monitor实现的锁属于重量级锁，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高，性能比较低。

每个 **Java 对象都可以关联一个 Monitor 对象**，如果使用 synchronized 给对象上锁(重量级)之后，该**对象头的Mark Word** 中就被设
置指向 Monitor 对象的指针

**`mark word`（标记字）是 Java 对象头的一部分，它存储了对象自身的运行时数据。锁的状态信息直接存储在 `mark word` 本身当中，锁的升级过程本质上就是 `mark word` 中比特位的含义变化和转换的过程。**

### 锁的升级与 Mark Word 的变化

`synchronized` 锁的优化过程（锁升级）就是围绕 `mark word` 展开的：

1. **无锁 (01)**
   - 一个新创建的对象，默认处于无锁状态。
   - 如果有计算过 `identity_hashcode`，会存储在这里。
2. **偏向锁 (Biased Locking) (01)**
   - **目的**：在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁就是为了让这个线程后续获取锁时**不需要任何同步操作（如CAS）**，代价最小。
   - **操作**：当第一个线程访问同步块时，通过 CAS 操作将其线程 ID 记录到 `mark word` 中，并将偏向锁标志位设为 `1`。以后这个线程再进入同步块时，只需要检查 `mark word` 中的线程ID是否是自己，如果是，则直接进入。
   - **与哈希码的冲突**：**一旦对象调用了 `hashCode()` 方法，偏向锁就会被撤销**，因为 `mark word` 没有空间同时存储哈希码和线程ID。
3. **轻量级锁 (Lightweight Locking) (00)**
   - **时机**：当有另一个线程来尝试获取偏向锁时（发生竞争），偏向锁就会升级为轻量级锁。
   - **操作**：JVM 会在当前线程的栈帧中创建一个名为 **锁记录 (Lock Record)** 的空间，然后将 `mark word` 复制过去。然后，JVM 使用 **CAS 操作**尝试将对象头的 `mark word` 替换为一个指向锁记录的指针。
     - 如果成功，当前线程就获得了锁。
     - 如果失败，表示其他线程也在竞争，当前线程会尝试通过 **自旋** 的方式等待锁。
   - 轻量级锁的“轻量”是相对于操作系统互斥量而言的，它通过**CAS和自旋**来避免直接进入内核态阻塞线程。
4. **重量级锁 (Heavyweight Locking) (10)**
   - **时机**：如果轻量级锁竞争激烈，某个线程自旋超过一定次数（JDK 6+ 是自适应自旋），轻量级锁就会升级为重量级锁。
   - **操作**：JVM 会向操作系统申请一个 **互斥量 (Mutex)**，并将 `mark word` 指向这个互斥量。所有未竞争到锁的线程都会被**阻塞**，等待操作系统的调度和唤醒。
   - 这是一个代价高昂的操作，会涉及到用户态到内核态的切换。

<img src="D:\在图片\JVM\029.png" style="zoom:67%;" />

![](D:\在图片\多线程\06.png)

**轻量级锁**

在很多的情况下，在Java程序运行时，同步块中的代码都是不存在竞争的，不同的线程**交替的执行**同步块中的代码。这种情况下，用重量级锁是没必要的。因此JVM引入了轻量级锁的概念。

**偏向锁**

轻量级锁在没有竞争时(就自己这个线程)，每次重入仍然需要执行 CAS 操作。

Java6 中引入了偏向锁来做进一步优化:只有第一次使用 CAS 将**线程 ID** 设置到对象的 Mark Word 头，之后发现这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有。

# 你谈谈 JMM(Java内存模型)

JMM 的核心目标是**确保**多线程环境下的**可见性、有序性和原子性**，从而避免由于**硬件和编译器**优化带来的不一致问题。

- JMM把内存分为两块，一块是私有线程的工作区域(工作内存)，一块是所有线程的共享区域(主内存)
- 线程跟线程之间是相互隔离，线程跟线程交互需要通过主内存

- JMM(Java Memory Model)Java内存模型，定义了**共享内存**中**多线程**程序读写**操作的行为规范**，通过这些规则来规范对**内存的读写**操作从而保证指令的正确性



- **可见性**：确保一个线程对变量的修改，能及时被其他线程看到。关键字 `volatile` 就是用来保证可见性的，它强制线程每次读写时都直接从主内存中获取最新值。
- **有序性**：指线程执行操作的顺序。JMM 允许某些指令重排序以提高性能，但不能**保证线程内的操作顺序不会被破坏**，可通过 `happens-before` 关系保证跨线程的有序性。
- **原子性**：是指操作不可分割，线程不会在执行过程中被中断。例如，`synchronized` 关键字能确保方法或代码块的原子性。

# CAS

CAS的全称是: Compare And swap(比较再交换)，它体现的一种乐观锁的思想，在无锁情况下保证线程操作共享数据的原子性。

CAS流程：一个当前内存值V、旧的预期值A、即将**更新的值B**，当且仅当**预期旧值A**和**内存值V**相同时，将内存值V修改为新值B并返回true，否则什么都不做，并返回false。如果CAS操作失败，通过自旋的方式等待并再次尝试，直到成功。

在JUC(java.util.concurrent)包下实现的很多类都用到了CAS操作：

AbstractQueuedSynchronizer(AQS框架)
AtomicXXX类

在操作**共享变量**的时候使用的**自旋锁**，效率上更高

CAS的底层是调用的Unsafe类中的**方法**，都是**操作系统**提供的，其他语言实现

CAS 是基于乐观锁的思想:最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，我吃亏再重试呗。

**ABA问题：**

使用多版本处理，在每一次CAS时加上一个版本号，预期值和内存值比较时会在进行版本号比较，如果版本号不同说明出现了ABA问题。**版本号通常与被修改的值存储在一起**。



# 请谈谈你对 volatile 的理解

① 保证线程间的可见性，因为它会**强制将修改后的值刷新**到主内存，并使其他线程的**本地缓存失效**。****

用 volatile 修饰共享变量，能够防止编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见。

如下图，JIT会优化代码。也可以使用加入vm参数-Xint表示禁用即时编译器不推荐，得不偿失(其他程序还要使用）

![](D:\在图片\多线程\08.png)

② **禁止进行指令重排序**。

用 volatile 修饰共享变量会在**读、写共享变量**时加入不同的**屏障**，阻止其他读写操作越过屏障，从而达到阻止重排序的效果

# 什么是AQS?

全称是 AbstractQueuedSynchronizer，即抽象队列同步器。它是**构建锁**或者其他同步组件的**基础框架**。

**AQS与Synchronized的区别**

Synchronized是关键字是C++实现的，AQS是java语言实现的。都属于悲观锁。

Synchronized：性能差锁竞争激烈都是重量级锁

AQS：锁竞争激烈的情况下，提供了多种解决方案

基于AQS常见的实现类：
ReentrantLock 阻塞式锁
Semaphore  基于计数的信号量
CountDownLatch 倒计时锁

- AQS内部维护了一个先进先出的双向队列，队列中存储的排队的线程
- 在AQS内部还有一个**属性state**，这个state就相当于是一个资源，默认是0(无锁状态)，如果队列中的有一个线程修改成功了state为1，则当前线程就相等于获取了资源
- 在对state修改的时候使用的cas操作，保证多个线程修改的情况下原子性

![](D:\在图片\多线程\09.png)

# ReentrantLock的实现原理

ReentrantLock翻译过来是可重入锁，相对于synchronized它具备以下特点:

- 可中断
- 可以设置超时时间
- 可以设置公平锁
- 支持多个条件变量
- 与synchronized一样，都支持重入
- 显式的获取和释放锁

ReentrantLock表示支持重新进入的锁，调用lock方 法获取了锁之后，再次调用 lock，是不会再阻塞

ReentrantLock主要利用**CAS+AQS**队列来实现

支持公平锁和非公平锁，在提供的构造器的中无参默认是非公平锁，也可以传参设置为公平锁

# synchronized和Lock有什么区别 ?

与AQS类似，Lock是接口，源码由Jdk提供由java语言编写。

**功能层面**

二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能

Lock 提供了许多 synchronized 不具备的功能，例如公平锁、可打断、可超时、多条件变量

Lock 有适合不同场景的实现，如 ReentrantLock，ReentrantReadWriteLock(读写锁)

**性能层面**

在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖

在竞争激烈时，Lock 的实现通常会提供更好的性能

# 死锁产生的条件是什么?

死锁:一个线程需要同时获取多把锁，这时就容易发生死锁

**如何进行死锁诊断?**

jps:输出JVM中运行的进程状态信息

jstack:查看java进程内线程的堆栈信息

# 聊一下ConcurrentHashMap

在JDK1.8中，放弃了Segment臃肿的设计，数据结构跟HashMap的数据结构是一样的:数组+红黑树+链表

加锁的方式
JDK1.7采用Segment分段锁，底层使用的是ReentrantLock

`ConcurrentHashMap` 内部的核心**数组** transient volatile Node<K,V>[] **table**（JDK 1.8+）被声明为 `volatile`。保证**可见性。**

JDK1.8采用CAS添加新节点，采用synchronized锁定链表或红黑二叉树的**首节点**，相对Segment分段**锁粒度更细**，性能更好

采用 CAS+Synchronized来保证并发安全进行实现

CAS控制数组节点的添加，保证并发的**原子性**

synchronized只**锁**定当前链表或红黑二叉树的首节点来保证**并发的有序性**，只要hash不冲突，就不会产生并发的问题，效率得到提升

# 导致并发程序出现问题的根本原因是什么

根本原因是**破坏了并发编程的三大特性**。

**原子性**:一个线程在CPU中操作不可暂停，也不可中断，要不执行完成，要不不执行

**内存可见性**:让一个线程对共享变量的修改对另一个线程可见

**有序性**：
指令重排:处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的

# 线程池

## 说一下线程池的核心参数，线程池的执行原理知道嘛

![](D:\在图片\多线程\10.png)

<img src="D:\在图片\多线程\13.png" style="zoom: 67%;" />

**corePoolSize** 核心线程数目

**maximumPoolSize** 最大线程数目=(核心线程+救急线程的最大数目)

**keepAliveTime** 生存时间-救急线程的生存时间，生存时间内没有新任务，此线程资源会释放

**unit** 时间单位-救急线程的生存时间单位，如秒、毫秒等

**workQueue**-当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务

**threadFactory** 线程工厂-可以定制线程对象的创建，例如设置线程名字、是否是守护线程等

**handler** 拒绝策略-当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略

<img src="D:\在图片\多线程\11.png" style="zoom: 67%;" />

## 线程池中有哪些常见的阻塞队列

ArrayBlockingQueue的LinkedBlockingQueue区别

ArrayBlockingQueue：必须给容量参数（有界），

LinkedBlockingQueue：可以无参数（无界），单向链表。

<img src="D:\在图片\多线程\12.png" style="zoom: 67%;" />

## 如何确定核心线程数

**IO密集型任务**
一般来说:文件读写、DB读写、网络请求等

**CPU密集型任务**
一般来说:计算型代码、Bitmap转换、Gson转换等

参考回答:
① 高并发、任务执行时间短→(CPU核数+1)，减少线程上下文的切换
② 并发不高、任务执行时间长
IO密集型的任务→(CPU核数*2+1)
计算密集型任务 →(CPU核数+1)
③ 并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考②。

## 线程池的种类有哪些

- newFixedThreadPool:创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
- newSingleThreadExecutor:创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO)执行
- newCachedThreadPool:创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程
- newScheduledThreadPool:可以执行延迟任务的线程池，支持定时及周期性任务执行

## 为什么不建议用Executors创建线程池

线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则规避资源耗尽的风险：

说明:Executors 返回的线程池对象的弊端如下
1)FixedThreadPool和 SingleThreadPool 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2)CachedThreadPool :
允许的创建线程数量为 Integer.MAX VALUE，可能会创建大量的线程，从而导致 OOM。 

## 线程池使用场景（CountDownLatch）

**多线程使用场景一(es数据批量导入)**



<img src="D:\在图片\多线程\14.png" style="zoom: 67%;" />

**多线程使用场景二(数据汇总)**

在一个电商网站中，用户下单之后，需要查询数据，数据包含了三部分:订单信息、包含的商品、物流信息;这三块信息都在不同的微服务中进行实现的，我们如何完成这个业务呢?

在实际开发的过程中，难免需要调用多个接口来汇总数据，如果所有接口(或部分接口)的没有依赖关系，就可以使用线程池+future来提升性能

<img src="D:\在图片\多线程\15.png" style="zoom: 67%;" />

**多线程使用场景三(异步调用)**

异步线程(线程池):为了避免下一级方法影响上一级方法(性能考虑)，可使用异步线程调用下一个方法(不需要下一级方法返回值)，可以提升方法响应时间

## 如何控制某个方法允许并发访问线程的数量（Semaphore）

**Semaphore**['sema for信号量，是JUC包下的一个工具类，底层是AQS，我们可以通过其限制执行的线程数量

使用场景:
通常用于那些资源有明确**访问数量限制**的场景，**常用于限流**

在多线程中提供了一个工具类Semaphore，信号量。在并发的情况下，可以控制方法的访问量

1. 创建Semaphore对象，可以给一个容量
2. acquire()可以请求一个信号量，这时候的信号量个数-1，信号量为负数时，请求会被阻塞。
3. release()释放一个信号量，此时信号量个数+1

<img src="D:\在图片\多线程\16.png" style="zoom: 67%;" />









# ThreadLocal

分析一下自己总结的 ThreadLocal原理 首先给面试官刷出这一套组合拳：先讲一下作用，再说自己看过源码，讲下源码 ThreadLocal就是让线程有一份自己的数据副本**是线程私有的（存储在 Thread 对象中），其他线程无法直接访问**，因此不需要考虑线程安全问题，在我做过的项目中一般用来**存储用户信息**。因为后台中每一个请求都是一个线程，我们在后续**需要这个数据**的时候就可以很方便的获取这个信息。 

当要存储多个不同类型值时，一个线程可以创建多个ThreadLocal对象。

ThreadLocal是解决线程安全的一个操作类，其中有一个**静态内部类**ThreadLocalMap，这个Map里面的key是ThreadLocal这个对象，value就是我们要存储的值。而ThreadLocalMap里面其实是维护了一个**Entry数组**，而Entry类是ThreadLocalMap的**静态内部类**，其中key存储的是弱引用的ThreadLocal，value存储的就是要存储的数据。而 `ThreadLocalMap` **本质上是线程私有的哈希表**。 

而在每条线程**Thread类**内部有一个ThreadLocal.ThreadLocalMap类型的成员变量**threadLocals字段**，这个threadLocals就是每条线程用来存储数据副本的，key值为ThreadLocal对象，value为变量副本。所以ThreadLocal和里面的静态内部类ThreadLocalMap其实是为每一个**线程来服务的**。在ThreadLocal源码中也可以看到，每次执行get和set方法的时候，都要**先获取当前访问的线程**，然后再从当前线程获取该线程的ThreadLocalMap属性然后再来操作。 如果面试官再问ThreadLocal会出现的问题，那就给他回答下面的，因为上面已经说过源码了，所以下面有一个强引用链就不再讲为什么了。 这套组合拳打的很好

 

# 追问：ThreadLocal可能出现的问题？

 ThreadLocal会发生内存泄漏的问题。 ThreadLocalMap里面维护了一个Entry数组，而每个Entry类的key是弱引用的ThreadLocal，value是数据。如果一个ThreadLocal对象没有外部的强引用来指向它，那么堆内存不足的时候会被GC掉这些弱引用的Key，那么就会出现key为null但是value不为null的情况，但是此时的value会一直存在一个强引用链，导致value 是强引用，它的引用链是：`Thread -> ThreadLocalMap -> Entry -> value`。只要**线程（Thread）还在存活**（如线程池中的核心线程长期不销毁），这条引用链就会一直存在，导致 value 无法被 GC 回收，这个value就是泄漏的对象。 但是ThreadLocalMap在执行get、set、remove的时候会自动清理key为null的Entry，但是更优雅的做法还是在使用完ThreadLocal之后调用ThreadLocal中的remove方法清空ThreadLocal变量副本解决该问题，在我做的项目中，会在过滤器的最后执行ThreadLocal中的remove方法进行手动释放。